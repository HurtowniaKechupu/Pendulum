import time
import gym
import numpy as np
import random
import math
env = gym.make('Pendulum-v0')

epsilon = 0.3
gamma = 1.05
alpha = 0.2

podzial_kata = 18
podzial_momentu = 4
podzial_akcji = 5

def oblicz_theta (y,x):
    if (x>0):
        return math.acos(y)
    else:
        return 2*math.pi - math.acos(y)



def aprox(number, amount,max):
    posit = int(math.floor(((number/max)+1)*amount/2))
    return posit


#Q_table = np.full((podzial_kata,podzial_momentu,podzial_akcji),0)
#Q_table = np.random.rand(podzial_kata,podzial_momentu,podzial_akcji)    #wypelnienie tabeli q losowo by bez informacji poczatkowej dzialalo
#Q_table = Q_table / 50      #podzielenie by wartości sie przypakowo nie zbiegały
Q_table =  [[[ 5.62380717e-03,1.42175596e-02,6.66113360e-03,3.23352750e-03,6.83119328e-03],
[ 6.89165468e-03,1.94286532e-02,1.99861967e-02,7.08288388e-03,8.16502081e-03],
[ 3.98647313e-03,1.69467423e-02,9.93700802e-03,5.68871848e-03,4.61478460e-03],
[ 1.79096866e-02,1.28377881e-02,1.91222460e-03,2.07667911e-03,1.24971202e-02]],

[[ 8.27670466e-03,1.96196988e-02,9.90053130e-03,5.25207104e-03,1.51229764e-02],
[ 1.71495648e-02,1.77167873e-02,1.29730962e-02,1.32168689e-02,1.44337411e-02],
[ 2.41811173e-03,1.14988361e-02,1.27056332e-02,4.74832769e-03,2.82155082e-03],
[ 1.59563231e-02,2.97100571e-03,2.88215380e-03,1.47958216e-02,4.77158644e-03]],

[[ 5.79735126e-03,8.32680807e-03,5.77423624e-03,3.70616020e-03,5.03080343e-03],
[ 1.70045794e-02,4.64820399e-03,1.91064313e-02,8.21642461e-03,2.88171010e-03],
[ 1.66400967e-02,1.83920228e-02,3.75729469e-03,1.28381045e-02,6.66598488e-03],
[ 1.09394012e-02,1.12772707e-02,1.69739488e-02,1.19788272e-03,8.51562276e-03]],

[[ 1.00073437e-02,9.50453721e-03,6.85958311e-03,1.84550303e-02,1.11235234e-02],
[ 1.37674082e-02,1.28574569e-02,1.79091010e-02,6.06669765e-03,8.36420696e-03],
[ 1.30820395e-02,5.78976070e-03,6.48167640e-03,1.44872639e-03,1.24294703e-02],
[ 1.40394989e-02,1.76315631e-02,5.81229852e-03,1.43040887e-02,8.18713969e-04]],

[[ 4.02067582e-03,8.26360068e-04,2.04821578e-03,1.64581216e-02,2.87073949e-03],
[ 1.65962787e-02,2.41259645e-03,5.11028657e-03,1.68565434e-02,2.70056726e-03],
[ 5.60122520e-04,1.21516672e-02,1.17498068e-02,1.33724386e-02,1.22120009e-02],
[ 8.65110899e-03,5.33019766e-03,3.53314125e-04,6.17735542e-03,1.12863532e-02]],

[[ 1.75857701e-02,1.71689847e-03,5.46528611e-03,4.04150501e-03,8.73936456e-03],
[ 1.97244771e-02,1.00993560e-03,4.44586296e-03,1.25902952e-02,1.52040153e-03],
[ 1.73318459e-02,4.19047799e-03,6.36950053e-03,1.50366282e-02,1.01355396e-02],
[ 7.18095508e-03,5.02491292e-03,1.64502294e-02,1.55996150e-02,1.33894485e-02]],

[[ 6.86400343e-03,9.28252455e-03,1.31086806e-02,1.47022511e-02,1.78129819e-05],
[ 8.45034662e-03,1.40133575e-02,6.42681800e-04,3.56379231e-03,4.57652229e-04],
[ 8.96247570e-03,7.92055118e-03,7.52696631e-03,7.98788904e-03,6.38379848e-03],
[ 5.35251910e-03,1.94260447e-02,1.38579978e-02,1.44395588e-02,1.34666096e-02]],

[[ 1.04194717e-02,1.29082521e-02,2.77151829e-03,8.67928556e-03,1.64383995e-02],
[ 9.49516447e-03,5.38778453e-03,1.59628230e-02,1.95734695e-02,7.96080672e-04],
[ 7.10300845e-03,1.71098903e-02,2.55874773e-03,8.25582022e-03,8.71707109e-04],
[ 2.41852986e-03,1.72112440e-02,7.63284715e-03,8.99253546e-03,1.03399726e-03]],

[[ 1.22052080e-02,1.04392012e-02,1.69284266e-03,3.38367144e-03,9.72579582e-03],
[ 5.63967853e-03,1.00694279e-02,1.08097100e-03,1.94429417e-02,1.43486031e-02],
[ 1.81312219e-02,7.76739117e-03,3.85322111e-03,5.90658524e-03,1.39304345e-02],
[ 7.79437912e-03,3.82545902e-03,1.64366685e-02,3.50040441e-03,1.69541499e-02]],

[[ 3.27348466e-03,4.08504275e-03,1.01729689e+00,5.98471713e-03,7.26895577e-03],
[ 2.26248538e+00,4.60517813e+00,3.38270399e+00,3.97536501e+00,4.71952455e+00],
[ 1.07191601e+00,1.19641344e+00,9.32472288e-01,8.30585367e-01,7.60495724e-01],
[-4.78154384e-01,-5.09771836e-01,-6.49607854e-02,-3.08706096e-01,-8.89943287e-01]],

[[ 3.64237366e-01,6.07907368e-01,6.22983942e-01,6.83831519e-01,3.99919450e+00],
[ 3.94541900e+00,3.47010886e+00,3.00911619e+00,2.37361123e+00,1.15787696e+00],
[-3.79083961e+00,-4.42607766e+00,-4.18323965e+00,-3.70602100e+00,-3.68243345e+00],
[-4.71163548e+00,-4.92059244e+00,-4.70519473e+00,-4.39786313e+00,-4.95440804e+00]],

[[-1.20303802e+00,-5.12907412e-01,1.05263672e+00,-1.37768173e+00,-1.02409069e+00],
[-5.00631908e+00,-4.67042538e+00,-4.63293935e+00,-4.85044922e+00,-5.28561406e+00],
[-7.46114018e+00,-7.39536542e+00,-7.80025692e+00,-6.62245911e+00,-7.99645415e+00],
[-5.99882274e+00,-6.02426871e+00,-6.10025234e+00,-6.19792365e+00,-5.49445039e+00]],

[[-4.10507587e+00,-3.18081851e+00,-3.75658371e+00,-4.71201142e+00,-3.38254802e+00],
[-9.74349710e+00,-9.67910824e+00,-8.04932089e+00,-9.94508828e+00,-9.81582286e+00],
[-1.11224369e+01,-1.11574821e+01,-1.09061573e+01,-1.04150662e+01,-8.14811333e+00],
[-5.09590317e+00,-5.95379992e+00,-5.78098225e+00,-4.78641491e+00,-3.46056755e+00]],

[[-4.58934278e+00,-6.08471631e+00,-5.50327401e+00,-5.86232142e+00,-5.60848415e+00],
[-1.12547001e+01,-1.49048770e+01,-1.47404451e+01,-1.51721061e+01,-1.48059058e+01],
[-1.39074905e+01,-1.42211920e+01,-1.40998885e+01,-1.43612601e+01,-1.29994875e+01],
[-4.69389047e+00,-2.56460497e+00,-2.05858352e+00,-3.61608542e+00,-3.35750017e+00]],

[[-6.14343806e+00,-6.70041065e+00,-6.57442288e+00,-6.47431752e+00,-6.64168474e+00],
[-1.26981242e+01,-1.19797651e+01,-1.20715041e+01,-1.19325472e+01,-1.09040743e+01],
[-9.59048341e+00,-9.13768540e+00,-8.79575681e+00,-6.48400285e+00,-8.59150970e+00],
[-8.10626772e-01,-1.25996976e+00,-9.87569359e-01,-1.11745782e+00,8.30098324e-02]],

[[-5.01270223e+00,-5.34776980e+00,-5.50332689e+00,-5.26249680e+00,-5.29202919e+00],
[-7.77446078e+00,-7.04506946e+00,-7.02382168e+00,-8.08621227e+00,-7.66816534e+00],
[-3.97260083e+00,-4.11027414e+00,-1.28946524e+00,-3.64631328e+00,-3.80587024e+00],
[ 2.13470941e+00,2.41196017e+00,2.63753491e+00,1.38353662e+00,3.50787873e+00]],

[[-1.41744144e+00,-1.61176429e+00,-1.01769282e+00,-7.17903361e-01,-1.51947068e+00],
[-2.20328965e+00,-2.20826540e+00,-2.47936608e+00,-2.29034072e+00,-2.60514163e+00],
[ 4.89508752e+00,3.68863060e+00,3.91517805e+00,6.16908607e+00,7.17432525e+00],
[ 4.46348055e+00,6.78740025e+00,1.27498405e+00,2.63572416e+00,2.30476573e+00]],

[[ 6.12012828e-03,1.54887917e-02,1.41996586e-03,1.07125052e-02,4.70240082e-03],
[ 1.25808561e+00,1.21208893e+00,1.92995987e+00,9.52164705e-01,1.73214081e+00],
[ 5.66649464e+00,5.50550161e+00,5.04647389e+00,5.90746914e+00,5.63619541e+00],
[ 4.73420245e+00,8.81924152e-03,3.08081566e+00,4.41967387e-02,8.83961981e-02]]]

Q_table = np.array(Q_table)
Q_table = (Q_table+10)/10

for i_episode in range(1000):
    state = env.reset() #reset środowiska

    y = state[0]
    x = state[1]
    th = oblicz_theta(y, x)
    pozycja_th = aprox(th, podzial_kata, 2 * math.pi)  # ustalenie pozycji dla kąta w tablicy q
    pozycja_momentu = aprox(state[2], podzial_momentu, 8)  # ustalenie pozycji dla momentu w tablicy q

    for t in range(100):
        env.render()    #render grafiki, chyba najlepsze miejsce



        if random.uniform(0, 1) < epsilon:
            # Check the action space
            action = env.action_space.sample()
            pozycja_akcji = aprox(action,podzial_akcji,2)   #obliczenie pozycji akcji w tabeli q
        else:
            # Check the learned values
            pozycja_akcji = np.argmax(Q_table[pozycja_th][pozycja_momentu])
            action = np.array([float(pozycja_akcji-2)/1])     #nie wiem co to -2.5/1.25 = (podzal_akcji-1/2)/((podzial_akcji-1)/4)




        next_state, reward, done, info = env.step(action)
        y = next_state[0]
        x = next_state[1]
        th = oblicz_theta(y,x)
        nowa_pozycja_th = aprox(th, podzial_kata, 2 * math.pi)
        nowa_pozycja_momentu = aprox(next_state[2], podzial_momentu, 8)

        if nowa_pozycja_momentu == podzial_momentu:             #nie mam najmniejszego pojecia dlaczego tak sie dzieje
            nowa_pozycja_momentu -= 1

        Q_value = alpha * ((reward+3)/9 + gamma * max(Q_table[nowa_pozycja_th][nowa_pozycja_momentu])- Q_table[pozycja_th][pozycja_momentu][pozycja_akcji])
        Q_table[pozycja_th][pozycja_momentu][pozycja_akcji] += Q_value

        pozycja_th = nowa_pozycja_th
        pozycja_momentu = nowa_pozycja_momentu

        print(Q_value,action,next_state,reward)
        if Q_value > 2:
            print("tutaj")


        #time.sleep(1)
        if done:
            print("Episode finished after {} timesteps".format(t + 1))
            break

print(Q_table)

env.close()




